<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>tp_cloud_opennebula</title>


<style type="text/css">
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}

kbd {
  display: inline-block;
  padding: 3px 5px;
  font-size: 11px;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb
}

* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>


</head>

<body>

<h1 id="toc_0">TP Cloud - OpenNebula</h1>

<h2 id="toc_1">Introduction</h2>

<p>Ce TP est à réaliser en <strong>binôme</strong> sur deux PC de la salle. Les PC sous Ubuntu 18.04 LTS seront apparentés à des serveurs physiques d&#39;un datacenter formant un cloud IAAS auto-hébergé avec la solution OpenNebula. Nous allons construire un cloud miniature composé de deux serveurs :</p>

<ul>
<li><strong>serveur A</strong> : frontend + stockage partagé + hyperviseur</li>
<li><strong>serveur B</strong> : hyperviseur</li>
</ul>

<p>La version stable préconisée de OpenNebula est la version <strong>6.0</strong> . Ce TP est basé sur la <a href="https://docs.opennebula.io/6.0/">documentation OpenNebula</a> disponible en ligne.</p>

<h2 id="toc_2">1. Prérequis du poste</h2>

<h3 id="toc_3">Formatage du poste</h3>

<p>Le TP nécessite la formatage du miniPC Optiplex5080 avec l&#39;image préinstallé de OpenNebula :</p>

<ul>
<li>Démarrer le boot PXE IPv4</li>
<li>Choisir <strong>Get images via NFS</strong></li>
<li>Language: <strong>en_US.UTF-8 English</strong></li>
<li>Keep default keyboard layout (US)</li>
<li>Start Clonezilla</li>
<li>Device-image</li>
<li>Skip (use existing /home/partimag)</li>
<li>Press &quot;Enter&quot; to continue</li>
<li>Beginner</li>
<li><strong>restoredisk</strong></li>
<li>Choisir : <strong>2022-02-21-14-cloud</strong> </li>
<li>nvme0n1 256GB... : Enter</li>
<li>-scr: No, skip checking the image before restoring</li>
<li>-p reboot</li>
<li>Press &quot;Enter&quot; to continue</li>
<li>Are you sure you want to continue: y and press &quot;Enter&quot;</li>
<li>Are you sure you want to continue: y and press &quot;Enter&quot;</li>
</ul>

<p><strong>Note:</strong> si le BIOS ne boot pas en PXE: </p>

<ul>
<li>Redémarrer le mini-PC en appuyant sur la touche F2 sur l&#39;écran DELL pour accéder au BIOS</li>
<li>Dans General &gt; Boot Sequence &gt; choisir Onboard NIC (IPv4) en premier (flèche vers le haut) </li>
<li>Cliquer sur Apply</li>
<li>Cocher la case <strong>Save as custom user settings</strong>, puis cliquer sur OK</li>
<li>Exit</li>
</ul>

<h3 id="toc_4">Configuration des noms de machines sur le serveur A et B</h3>

<p>Editer le fichier <strong>/etc/hosts</strong></p>

<ul>
<li>Supprimer la ligne présente par défaut:</li>
</ul>

<div><pre><code class="language-none">172.0.1.1 Optiplex5080</code></pre></div>

<ul>
<li>Adapter les lignes suivantes au <strong>serveur A</strong> et <strong>serveur B</strong> du binome. Il faut utiliser l&#39;adresse IPv4 du PC sur l&#39;interface eno2 (dans un terminal taper la commande <code>ip addr show eno2</code>)</li>
</ul>

<div><pre><code class="language-none">192.168.15.A    nodeA
192.168.15.B    nodeB</code></pre></div>

<p>Par exemple:</p>

<div><pre><code class="language-none">192.168.15.11   node11
192.168.15.12   node12</code></pre></div>

<p>Sur le <strong>serveur A</strong>, lancer la commande suivante:</p>

<div><pre><code class="language-none">sudo hostnamectl set-hostname node11</code></pre></div>

<p>Sur le <strong>serveur B</strong>, lancer la commande suivante:</p>

<div><pre><code class="language-none">sudo hostnamectl set-hostname node12</code></pre></div>

<h2 id="toc_5">2. Démarrage du Front-end (serveur A)</h2>

<p>Référence : <a href="https://docs.opennebula.io/6.0/installation_and_configuration/frontend_installation/index.html">installation du front-end</a></p>

<h3 id="toc_6">Démarrage de OpenNebula</h3>

<ul>
<li>Démarrage des démons OpenNebula et de l&#39;interface web Sunstone</li>
</ul>

<div><pre><code class="language-none">sudo systemctl start opennebula
sudo systemctl start opennebula-sunstone</code></pre></div>

<ul>
<li>Se connecter en tant qu&#39;utilisateur <em>oneadmin</em>:</li>
</ul>

<div><pre><code class="language-none">sudo su oneadmin</code></pre></div>

<p>Vérification de l&#39;installation</p>

<div><pre><code class="language-none">   oneuser show
USER 0 INFORMATION
ID              : 0
NAME            : oneadmin
GROUP           : oneadmin
PASSWORD        : XXX
AUTH_DRIVER     : core
ENABLED         : Yes

USER TEMPLATE
TOKEN_PASSWORD=&quot;XXX&quot;

RESOURCE USAGE &amp; QUOTAS                                 </code></pre></div>

<p>Note, le mot de passe autogénéré de l&#39;utilisateur <em>oneadmin</em> se trouve dans le fichier <code>/var/lib/one/.one/one_auth</code> :</p>

<div><pre><code class="language-none">cat /var/lib/one/.one/one_auth 
oneadmin:XXXXXXXXXXXX</code></pre></div>

<p>Vous pouvez vous connecter sur l&#39;interface web en utilisant le login <em>oneadmin</em> avec le mot de passe trouvé ci-dessus.</p>

<p><a href="http://localhost:9869">http://localhost:9869</a></p>

<p><strong>Note</strong>: Pour se connecter depuis un autre poste de la salle <a href="http://192.168.X.Y:9869/">http://192.168.X.Y:9869/</a>
, il faut autoriser le démon opennebula-sunstone à écouter sur le toutes les interfaces réseaux :</p>

<p>Editer le fichier <code>/etc/one/sunstone-server.conf</code></p>

<div><pre><code class="language-none"># Server Configuration
#
:host: 0.0.0.0
:port: 9869</code></pre></div>

<p>Puis redémarrer opennebula-sunstone :</p>

<div><pre><code class="language-none">sudo systemctl restart opennebula-sunstone</code></pre></div>

<h3 id="toc_7">Déclarer le front-end comme hyperviseur</h3>

<p>Le front-end est actif mais n&#39;a pas encore d&#39;hyperviseur associé. Nous allons utiliser les ressources matérielles du front-end pour l&#39;utiliser également comme hyperviseur.</p>

<p>Références: <a href="https://docs.opennebula.io/6.0/open_cluster_deployment/kvm_node/index.html">https://docs.opennebula.io/6.0/open<em>cluster</em>deployment/kvm_node/index.html</a></p>

<p><strong>Ajout d&#39;un hôte</strong></p>

<p>Voir la documentation détaillée de l&#39;<a href="https://docs.opennebula.io/6.0/open_cluster_deployment/kvm_node/kvm_node_installation.html#step-7-adding-host-to-opennebula">ajout d&#39;un hôte à OpenNebula</a></p>

<ul>
<li><p>Aller sur la page d&#39;administration &gt; Infrastructure &gt; Hosts <a href="http://localhost:9869/#hosts-tab">http://localhost:9869/#hosts-tab</a></p></li>
<li><p>Cliquer sur l&#39;icône verte <strong>+</strong> et compléter les informations du formulaire en remplacant <em>192.168.15.A</em> par l&#39;IPv4 du PC sur l&#39;interface <strong>eno2</strong> (dans un terminal taper la commande <code>ip addr show eno2</code>)</p></li>
</ul>

<div><pre><code class="language-none">Type: KVM
Cluster: default
Hostname: 192.168.15.A</code></pre></div>

<ul>
<li>Valider en cliquant sur l&#39;icône verte <strong>Create</strong></li>
</ul>

<p>Si une erreur apparait après l&#39;ajout de l&#39;hôte, vérifier le fichier de log <code>/var/log/one/oned.log</code>. généralement lié à un problème de connexion SSH (voir plus haut).</p>

<h3 id="toc_8">Activer le stockage partagé</h3>

<ul>
<li><p>Aller sur la page d&#39;administration &gt; Storage &gt; Datastores <a href="http://localhost:9869/#datastores-tab">http://localhost:9869/#datastores-tab</a></p></li>
<li><p>Dans Datastores &gt; 0 System :</p></li>
</ul>

<div><pre><code class="language-none">TM_MAD : shared</code></pre></div>

<ul>
<li>Dans Datastores &gt; 1 Default :</li>
</ul>

<div><pre><code class="language-none">TM_MAD : shared</code></pre></div>

<h2 id="toc_9">3. Ajout d&#39;un réseau virtuel</h2>

<p>Il nous manque le paramètrage réseau pour les VMs, sans quoi on ne pourrait pas les joindre à distance :</p>

<ul>
<li>un réseau privé IPv4 de type NAT dans un LAN propagé entre le serveur A et B</li>
</ul>

<h3 id="toc_10">Frontend Fix Ubuntu</h3>

<p>Désactiver Network-Manager, attention la connectivé réseau sur l&#39;interface primaire va expirer (lease DHCP)</p>

<div><pre><code class="language-none">sudo systemctl stop NetworkManager-wait-online.service
sudo systemctl stop NetworkManager-dispatcher.service
sudo systemctl stop network-manager.service</code></pre></div>

<p>Activer DHCP sur l&#39;interface ethernet primaire:</p>

<div><pre><code class="language-none">sudo dhclient eno2</code></pre></div>

<p>Autoriser libvirt à gérer les interfaces réseaux virtuelles:</p>

<p>Réf: https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1815910 </p>

<p>Editer <code>/etc/apparmor.d/abstractions/libvirt-qemu</code> et ajouter :</p>

<div><pre><code class="language-none">/dev/vhost-net rw,</code></pre></div>

<p>Redémarrer apparmor:</p>

<div><pre><code class="language-none">sudo systemctl restart apparmor</code></pre></div>

<h3 id="toc_11">Création du bridge sur l&#39;hyperviseur</h3>

<ul>
<li>Création du bridge</li>
</ul>

<p><strong>NOTE</strong>: remplacer eth1 par la deuxième interface Ethernet/USB du mini PC (par ex <strong>enx00e04</strong>...)</p>

<div><pre><code class="language-none">sudo brctl addbr br1
sudo ip link set br1 up
sudo ip link set eth1 up
sudo brctl addif br1 eth1
sudo ip addr add 10.4.2.254/24 dev br1</code></pre></div>

<ul>
<li>Ajouter une règle iptables NAT sur l&#39;interface connecté à Internet, eno2:</li>
</ul>

<div><pre><code class="language-none">sudo iptables -t nat -A POSTROUTING -o eno2 -j MASQUERADE</code></pre></div>

<h3 id="toc_12">Ajout du réseau type dans OpenNebula</h3>

<ul>
<li><p>Aller sur la page d&#39;administration &gt; Network &gt; Virtual Networks <a href="http://localhost:9869/#vnets-tab">http://localhost:9869/#vnets-tab</a></p></li>
<li><p>Cliquer sur l&#39;icône verte <strong>+</strong> et compléter les informations du formulaire :</p></li>
</ul>

<p><strong>General</strong></p>

<div><pre><code class="language-none">Name: br1
Cluster: default
Description: NAT br1</code></pre></div>

<p><strong>Conf</strong></p>

<div><pre><code class="language-none">Bridge: br1
Network mode: Custom
VN_MAD: dummy</code></pre></div>

<p><strong>Addresses</strong></p>

<div><pre><code class="language-none">First IPv4 address: 10.4.2.1
Size: 253</code></pre></div>

<p><strong>Context</strong></p>

<div><pre><code class="language-none">Network address: 10.4.2.0
Network mask: 24
Gateway: 10.4.2.254
DNS: 130.79.200.200</code></pre></div>

<h2 id="toc_13">4. Configuration du compte utilisateur</h2>

<p>Ajouter de la clé SSH publique déployée dans les VMs pour se connecter en root via SSH :</p>

<ul>
<li>Aller sur la page d&#39;administration &gt; Oneadmin &gt; Settings <a href="http://localhost:9869/#settings-tab">http://localhost:9869/#settings-tab</a> &gt; Auth  et éditer le champ <code>Public SSH Key</code> en ajoutant la clé SSH publique de l&#39;utilisateur par défaut du poste de travail, <em>info</em>.</li>
</ul>

<h2 id="toc_14">5. Création d&#39;une VM</h2>

<p>Voir la documentation détaillée de la <a href="https://docs.opennebula.io/6.0/management_and_operations/vm_management/index.html">gestion d&#39;une machine virtuelle</a>.</p>

<h3 id="toc_15">Téléchargement des images</h3>

<ul>
<li>Aller sur la page d&#39;administration &gt; Storage &gt; Apps <a href="http://localhost:9869/#marketplaceapps-tab">http://localhost:9869/#marketplaceapps-tab</a></li>
<li>Sélectionner l&#39;image <strong>Ubuntu 20.04</strong> (pas la minimal) et cliquer sur l&#39;icone avec le nuage et la flêche pour télécharger l&#39;image</li>
<li>Vérifer le bon téléchargement puis la création automatique du template de VM sur <a href="http://localhost:9869/#templates-tab">http://localhost:9869/#templates-tab</a></li>
</ul>

<h3 id="toc_16">Création d&#39;une VM</h3>

<ul>
<li>Aller sur la page d&#39;administration &gt; Instances &gt; VMs <a href="http://localhost:9869/#vms-tab">http://localhost:9869/#vms-tab</a></li>
<li>Cliquer sur l&#39;icône verte <strong>+</strong> </li>
<li>Sélectionner le template <strong>Ubuntu 20.04</strong> installé précédemment</li>
<li>Compléter les informations du formulaire :</li>
</ul>

<div><pre><code class="language-none">Persistent: non
VM Name: test1
Number of instance: 1
Memory: 768MB
Disk: 10GB
CPU: 1 
Network &gt; + Network Interface &gt; br1
Datastores &gt; default</code></pre></div>

<ul>
<li>Cliquer sur l&#39;icône verte <strong>Create</strong> en haut de la page pour lancer le déploiement de la VM.</li>
<li>Vérifer que le status de la VM passe à <em>running</em>. Cliquer sur l&#39;icône VNC pour voir la console de la VM. Se connecter sur la VM en root via SSH depuis l&#39;hyperviseur avec le compte <em>info</em> :</li>
</ul>

<div><pre><code class="language-none">ssh root@&lt;ip vm&gt;</code></pre></div>

<h2 id="toc_17">6. Ajout d&#39;un second hyperviseur à OpenNebula (serveur B)</h2>

<p>Nous allons utiliser le deuxième PC comme nouvel hôte OpenNebula. Il n&#39;est pas nécessaire de lancer le frontend (opennebula) ni l&#39;interface web (opennebula-sunstone).</p>

<h3 id="toc_18">Configuration du stockage partagé NFS</h3>

<ul>
<li>Sur le nouvel hôte, editer le fichier <code>/etc/fstab</code>, adapter avec l&#39;IPv4 du frontend 192.168.15.A</li>
</ul>

<div><pre><code class="language-none">&lt;ip_front_end&gt;:/var/lib/one/datastores/0  /var/lib/one/datastores/0  nfs   soft,intr,rsize=32768,wsize=32768,auto,vers=4
&lt;ip_front_end&gt;:/var/lib/one/datastores/1  /var/lib/one/datastores/1  nfs   soft,intr,rsize=32768,wsize=32768,auto,vers=4
&lt;ip_front_end&gt;:/var/lib/one/datastores/2  /var/lib/one/datastores/2  nfs   soft,intr,rsize=32768,wsize=32768,auto,vers=4</code></pre></div>

<ul>
<li>Monter la partition distante NFS dans le système </li>
</ul>

<div><pre><code class="language-none">mount /var/lib/one/datastores/0
mount /var/lib/one/datastores/1
mount /var/lib/one/datastores/2</code></pre></div>

<h3 id="toc_19">Configuration réseau</h3>

<ul>
<li>Autoriser libvirt à gérer les interfaces réseaux virtuelles:</li>
</ul>

<p>Réf: https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1815910 </p>

<p>Editer <code>/etc/apparmor.d/abstractions/libvirt-qemu</code> et ajouter :</p>

<div><pre><code class="language-none">/dev/vhost-net rw,</code></pre></div>

<p>Redémarrer apparmor:</p>

<div><pre><code class="language-none">sudo systemctl restart apparmor</code></pre></div>

<ul>
<li><p>Désactiver Network-Manager comme sur le frontend</p></li>
<li><p>Sur le serveur B, ajouter l&#39;interface br1 avec la deuxième interface ethernet eth1 comme pour le serveur A, sans déclarer d&#39;IP sur le bridge. Seul le front-end est la passerelle du réseau.</p></li>
</ul>

<p><strong>NOTE</strong>: remplacer eth1 par la deuxième interface Ethernet/USB du mini PC.</p>

<div><pre><code class="language-none">brctl addbr br1
ip link set br1 up
ip link set eth1 up
brctl addif br1 eth1</code></pre></div>

<p>Enfin, à l&#39;aide d&#39;un câble Ethernet, relier directement les deux interface USB/Ethernet.</p>

<h3 id="toc_20">Ajout d&#39;un hôte</h3>

<ul>
<li>Depuis le front-end, déclarer le nouvel hôte dans l&#39;infrastructure, utiliser l&#39;adresse IPv4 192.168.15.B du second PC.</li>
</ul>

<h3 id="toc_21">Création d&#39;une VM</h3>

<ul>
<li><p>Depuis le front-end, créer une nouvelle VM avec les paramètres suivants :</p>

<ul>
<li>image <strong>Ubuntu 20.04</strong></li>
<li>Réseau virtuel <strong>br1</strong></li>
</ul></li>
<li><p>Afin de répartir la charge du cloud, la seconde VM devrait être créé sur le <strong>serveur B</strong></p></li>
</ul>

<h2 id="toc_22">7. Migration à chaud</h2>

<ul>
<li><p>Dans la liste des VMs, essayer de <strong>déplacer à chaud</strong> une VM à l&#39;état <em>running</em> . Pendant la phase de migration, garder une connexion SSH ouverte dans la VM, et faire tourner un ping vers google.com. Tester les migrations de VM suivantes :</p>

<ul>
<li>dans le sens serveur A (front-end ) vers le serveur B</li>
<li>dans le sens serveur B vers le serveur A (front-end ) </li>
</ul></li>
</ul>

<h2 id="toc_23">8. Industrialisation</h2>

<p>Cette dernière partie du TP explore les possibilités pour automatiser la création à grande échelle de VMs sur le Cloud.</p>

<h3 id="toc_24">Installation Ansible</h3>

<ul>
<li>Installer Ansible sur le frontend</li>
</ul>

<div><pre><code class="language-none">sudo apt-get install virtualenv python3-pyone</code></pre></div>

<div><pre><code class="language-none">mkdir -p ~/python-env/
cd python-env
virtualenv ansible
source ~/python-env/ansible/bin/activate
pip install ansible</code></pre></div>

<h3 id="toc_25">Création de VMs via Ansible</h3>

<p>Référence : <a href="https://docs.ansible.com/ansible/latest/collections/community/general/one_vm_module.html">Module One VM Ansible</a></p>

<ul>
<li>Creer un fichier d&#39;inventaire ansible <code>inventory</code></li>
</ul>

<div><pre><code class="language-none">frontend ansible_host=127.0.0.1</code></pre></div>

<ul>
<li>Créer le fichier playbook <code>create_vm.yml</code> contenant les paramètres de la VM</li>
</ul>

<div><pre><code class="language-none">---
- hosts: frontend
  remote_user: root
  become: yes
  become_user: oneadmin
  vars:
      ansible_python_interpreter: &#39;/usr/bin/python3&#39;

  tasks:
  - one_vm:
      api_url: http://localhost:2633/RPC2
      attributes:
        name: myvmname
      # Ubuntu 20.04 on frontend
      template_id: 0
      disk_size: 20 GB
      memory: 2 GB
      vcpu: 2
      cpu: 1
      count: 1
      networks:
        - NETWORK: &quot;br1&quot;
          IP: 10.4.2.123
          SECURITY_GROUPS: &quot;0&quot;
</code></pre></div>

<ul>
<li>Lancer le playbook avec la commande suivante</li>
</ul>

<p><strong>Attention</strong>: il faudra astucieusement ajouter la clé publique de l&#39;utilisateur courant <code>info</code> pour l&#39;utilisateur <code>root</code> sur le frontend</p>

<div><pre><code class="language-none">ansible-playbook -i inventory create_vm.yml</code></pre></div>




</body>

</html>
